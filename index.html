<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BSKNet</title>

    <style>
        html,
        body {
            width: 100%;
            height: 100%;
            margin: 0px;
            padding: 0px;
        }





        input {
            width: 200px;
        }
    </style>
</head>

<body>
    <div style="margin:auto;max-width: 666px;text-align:justify">
                    <h1 style="text-align: center;">BWFNet: 3D Building Reconstruction from Single Off-Nadir Remote
Sensing Image with Semi-Weak Supervisions</h1>
                    <h3 style="text-align: center;"><a href="BSKNet.pdf">Paper</a>&emsp;<a href="https://github.com/ShaoRuizhe/BWFNet">Code</a></h3>
                    <div style="text-align:center"><img style="width: 600px;" src="image1.png"></div>
                    <div style="margin:auto;max-width: 666px;text-align:justify">
                        Rapid 3D building reconstruction in urban-scale areas has emerged as a pivotal technology for
                        smart city applications. Recent methods that reconstruct buildings from single off-nadir imagery
                        have gained attention due to their efficiency in both time and data costs. However, the training
                        of these methods relies on large-scale, costly 3D annotations, including building bounding
                        boxes, roofs, footprints, and roof-to-footprint offsets, and thus cannot be trained when only
                        the footprint is available, despite the fact that a large amount of building footprints can be
                        easily obtained in crowdsourced building data set form the Internet. To address this, we propose
                        a semi-weakly supervised learning method that leverages massive weakly annotated data
                        (footprints) and a limited number of manually annotated 3D building labels to learn to
                        reconstruct 3D buildings. In our method, we introduce an ingenious wireframe representation to
                        replace conventional bounding-box representation, thereby providing a foundation for semi-weakly
                        supervised learning. Based on this representation, we propose BWFNet for extracting building
                        wireframes. BWFNet enhances accuracy under semi-weakly supervision by modeling both structural
                        and local knowledge. Furthermore, we propose a training strategy for building wireframe
                        extraction grounded in the principle of geometric consistency constraints to further improve
                        weakly supervised performance. The experimental results demonstrate that the proposed BWFNet
                        achieves excellent reconstruction performance by utilizing only 3% fully annotated data combined
                        with weakly supervised samples. This performance represents a significant improvement compared
                        to current state-of-the-art methods.
                    </div>



    </div>
</body>

</html>